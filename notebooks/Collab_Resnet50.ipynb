{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940ac4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e71ceeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class block(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, image_channels, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            image_channels, 64, kernel_size=7, stride=2, padding=3, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_downsample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_downsample, stride)\n",
    "        )\n",
    "\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        for i in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff80f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(img_channel=1, num_classes=6):\n",
    "    return ResNet(block, [3, 4, 6, 3], img_channel, num_classes)\n",
    "\n",
    "def test():\n",
    "    BATCH_SIZE = 16\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = ResNet50(img_channel=1, num_classes=6).to(device)\n",
    "\n",
    "    input_tensor = torch.randn(BATCH_SIZE, 1, 64, 64).to(device)\n",
    "    y = net(input_tensor)\n",
    "\n",
    "    assert y.size() == torch.Size([BATCH_SIZE, 6])\n",
    "    print(\"Output shape:\", y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86176c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 6])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3d82a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [32, 64, 32, 32]           3,136\n",
      "       BatchNorm2d-2           [32, 64, 32, 32]             128\n",
      "              ReLU-3           [32, 64, 32, 32]               0\n",
      "         MaxPool2d-4           [32, 64, 16, 16]               0\n",
      "            Conv2d-5           [32, 64, 16, 16]           4,096\n",
      "       BatchNorm2d-6           [32, 64, 16, 16]             128\n",
      "              ReLU-7           [32, 64, 16, 16]               0\n",
      "            Conv2d-8           [32, 64, 16, 16]          36,864\n",
      "       BatchNorm2d-9           [32, 64, 16, 16]             128\n",
      "             ReLU-10           [32, 64, 16, 16]               0\n",
      "           Conv2d-11          [32, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-12          [32, 256, 16, 16]             512\n",
      "           Conv2d-13          [32, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-14          [32, 256, 16, 16]             512\n",
      "             ReLU-15          [32, 256, 16, 16]               0\n",
      "            block-16          [32, 256, 16, 16]               0\n",
      "           Conv2d-17           [32, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-18           [32, 64, 16, 16]             128\n",
      "             ReLU-19           [32, 64, 16, 16]               0\n",
      "           Conv2d-20           [32, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-21           [32, 64, 16, 16]             128\n",
      "             ReLU-22           [32, 64, 16, 16]               0\n",
      "           Conv2d-23          [32, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-24          [32, 256, 16, 16]             512\n",
      "             ReLU-25          [32, 256, 16, 16]               0\n",
      "            block-26          [32, 256, 16, 16]               0\n",
      "           Conv2d-27           [32, 64, 16, 16]          16,384\n",
      "      BatchNorm2d-28           [32, 64, 16, 16]             128\n",
      "             ReLU-29           [32, 64, 16, 16]               0\n",
      "           Conv2d-30           [32, 64, 16, 16]          36,864\n",
      "      BatchNorm2d-31           [32, 64, 16, 16]             128\n",
      "             ReLU-32           [32, 64, 16, 16]               0\n",
      "           Conv2d-33          [32, 256, 16, 16]          16,384\n",
      "      BatchNorm2d-34          [32, 256, 16, 16]             512\n",
      "             ReLU-35          [32, 256, 16, 16]               0\n",
      "            block-36          [32, 256, 16, 16]               0\n",
      "           Conv2d-37          [32, 128, 16, 16]          32,768\n",
      "      BatchNorm2d-38          [32, 128, 16, 16]             256\n",
      "             ReLU-39          [32, 128, 16, 16]               0\n",
      "           Conv2d-40            [32, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-41            [32, 128, 8, 8]             256\n",
      "             ReLU-42            [32, 128, 8, 8]               0\n",
      "           Conv2d-43            [32, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-44            [32, 512, 8, 8]           1,024\n",
      "           Conv2d-45            [32, 512, 8, 8]         131,072\n",
      "      BatchNorm2d-46            [32, 512, 8, 8]           1,024\n",
      "             ReLU-47            [32, 512, 8, 8]               0\n",
      "            block-48            [32, 512, 8, 8]               0\n",
      "           Conv2d-49            [32, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-50            [32, 128, 8, 8]             256\n",
      "             ReLU-51            [32, 128, 8, 8]               0\n",
      "           Conv2d-52            [32, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-53            [32, 128, 8, 8]             256\n",
      "             ReLU-54            [32, 128, 8, 8]               0\n",
      "           Conv2d-55            [32, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-56            [32, 512, 8, 8]           1,024\n",
      "             ReLU-57            [32, 512, 8, 8]               0\n",
      "            block-58            [32, 512, 8, 8]               0\n",
      "           Conv2d-59            [32, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-60            [32, 128, 8, 8]             256\n",
      "             ReLU-61            [32, 128, 8, 8]               0\n",
      "           Conv2d-62            [32, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-63            [32, 128, 8, 8]             256\n",
      "             ReLU-64            [32, 128, 8, 8]               0\n",
      "           Conv2d-65            [32, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-66            [32, 512, 8, 8]           1,024\n",
      "             ReLU-67            [32, 512, 8, 8]               0\n",
      "            block-68            [32, 512, 8, 8]               0\n",
      "           Conv2d-69            [32, 128, 8, 8]          65,536\n",
      "      BatchNorm2d-70            [32, 128, 8, 8]             256\n",
      "             ReLU-71            [32, 128, 8, 8]               0\n",
      "           Conv2d-72            [32, 128, 8, 8]         147,456\n",
      "      BatchNorm2d-73            [32, 128, 8, 8]             256\n",
      "             ReLU-74            [32, 128, 8, 8]               0\n",
      "           Conv2d-75            [32, 512, 8, 8]          65,536\n",
      "      BatchNorm2d-76            [32, 512, 8, 8]           1,024\n",
      "             ReLU-77            [32, 512, 8, 8]               0\n",
      "            block-78            [32, 512, 8, 8]               0\n",
      "           Conv2d-79            [32, 256, 8, 8]         131,072\n",
      "      BatchNorm2d-80            [32, 256, 8, 8]             512\n",
      "             ReLU-81            [32, 256, 8, 8]               0\n",
      "           Conv2d-82            [32, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-83            [32, 256, 4, 4]             512\n",
      "             ReLU-84            [32, 256, 4, 4]               0\n",
      "           Conv2d-85           [32, 1024, 4, 4]         262,144\n",
      "      BatchNorm2d-86           [32, 1024, 4, 4]           2,048\n",
      "           Conv2d-87           [32, 1024, 4, 4]         524,288\n",
      "      BatchNorm2d-88           [32, 1024, 4, 4]           2,048\n",
      "             ReLU-89           [32, 1024, 4, 4]               0\n",
      "            block-90           [32, 1024, 4, 4]               0\n",
      "           Conv2d-91            [32, 256, 4, 4]         262,144\n",
      "      BatchNorm2d-92            [32, 256, 4, 4]             512\n",
      "             ReLU-93            [32, 256, 4, 4]               0\n",
      "           Conv2d-94            [32, 256, 4, 4]         589,824\n",
      "      BatchNorm2d-95            [32, 256, 4, 4]             512\n",
      "             ReLU-96            [32, 256, 4, 4]               0\n",
      "           Conv2d-97           [32, 1024, 4, 4]         262,144\n",
      "      BatchNorm2d-98           [32, 1024, 4, 4]           2,048\n",
      "             ReLU-99           [32, 1024, 4, 4]               0\n",
      "           block-100           [32, 1024, 4, 4]               0\n",
      "          Conv2d-101            [32, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-102            [32, 256, 4, 4]             512\n",
      "            ReLU-103            [32, 256, 4, 4]               0\n",
      "          Conv2d-104            [32, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-105            [32, 256, 4, 4]             512\n",
      "            ReLU-106            [32, 256, 4, 4]               0\n",
      "          Conv2d-107           [32, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-108           [32, 1024, 4, 4]           2,048\n",
      "            ReLU-109           [32, 1024, 4, 4]               0\n",
      "           block-110           [32, 1024, 4, 4]               0\n",
      "          Conv2d-111            [32, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-112            [32, 256, 4, 4]             512\n",
      "            ReLU-113            [32, 256, 4, 4]               0\n",
      "          Conv2d-114            [32, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-115            [32, 256, 4, 4]             512\n",
      "            ReLU-116            [32, 256, 4, 4]               0\n",
      "          Conv2d-117           [32, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-118           [32, 1024, 4, 4]           2,048\n",
      "            ReLU-119           [32, 1024, 4, 4]               0\n",
      "           block-120           [32, 1024, 4, 4]               0\n",
      "          Conv2d-121            [32, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-122            [32, 256, 4, 4]             512\n",
      "            ReLU-123            [32, 256, 4, 4]               0\n",
      "          Conv2d-124            [32, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-125            [32, 256, 4, 4]             512\n",
      "            ReLU-126            [32, 256, 4, 4]               0\n",
      "          Conv2d-127           [32, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-128           [32, 1024, 4, 4]           2,048\n",
      "            ReLU-129           [32, 1024, 4, 4]               0\n",
      "           block-130           [32, 1024, 4, 4]               0\n",
      "          Conv2d-131            [32, 256, 4, 4]         262,144\n",
      "     BatchNorm2d-132            [32, 256, 4, 4]             512\n",
      "            ReLU-133            [32, 256, 4, 4]               0\n",
      "          Conv2d-134            [32, 256, 4, 4]         589,824\n",
      "     BatchNorm2d-135            [32, 256, 4, 4]             512\n",
      "            ReLU-136            [32, 256, 4, 4]               0\n",
      "          Conv2d-137           [32, 1024, 4, 4]         262,144\n",
      "     BatchNorm2d-138           [32, 1024, 4, 4]           2,048\n",
      "            ReLU-139           [32, 1024, 4, 4]               0\n",
      "           block-140           [32, 1024, 4, 4]               0\n",
      "          Conv2d-141            [32, 512, 4, 4]         524,288\n",
      "     BatchNorm2d-142            [32, 512, 4, 4]           1,024\n",
      "            ReLU-143            [32, 512, 4, 4]               0\n",
      "          Conv2d-144            [32, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-145            [32, 512, 2, 2]           1,024\n",
      "            ReLU-146            [32, 512, 2, 2]               0\n",
      "          Conv2d-147           [32, 2048, 2, 2]       1,048,576\n",
      "     BatchNorm2d-148           [32, 2048, 2, 2]           4,096\n",
      "          Conv2d-149           [32, 2048, 2, 2]       2,097,152\n",
      "     BatchNorm2d-150           [32, 2048, 2, 2]           4,096\n",
      "            ReLU-151           [32, 2048, 2, 2]               0\n",
      "           block-152           [32, 2048, 2, 2]               0\n",
      "          Conv2d-153            [32, 512, 2, 2]       1,048,576\n",
      "     BatchNorm2d-154            [32, 512, 2, 2]           1,024\n",
      "            ReLU-155            [32, 512, 2, 2]               0\n",
      "          Conv2d-156            [32, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-157            [32, 512, 2, 2]           1,024\n",
      "            ReLU-158            [32, 512, 2, 2]               0\n",
      "          Conv2d-159           [32, 2048, 2, 2]       1,048,576\n",
      "     BatchNorm2d-160           [32, 2048, 2, 2]           4,096\n",
      "            ReLU-161           [32, 2048, 2, 2]               0\n",
      "           block-162           [32, 2048, 2, 2]               0\n",
      "          Conv2d-163            [32, 512, 2, 2]       1,048,576\n",
      "     BatchNorm2d-164            [32, 512, 2, 2]           1,024\n",
      "            ReLU-165            [32, 512, 2, 2]               0\n",
      "          Conv2d-166            [32, 512, 2, 2]       2,359,296\n",
      "     BatchNorm2d-167            [32, 512, 2, 2]           1,024\n",
      "            ReLU-168            [32, 512, 2, 2]               0\n",
      "          Conv2d-169           [32, 2048, 2, 2]       1,048,576\n",
      "     BatchNorm2d-170           [32, 2048, 2, 2]           4,096\n",
      "            ReLU-171           [32, 2048, 2, 2]               0\n",
      "           block-172           [32, 2048, 2, 2]               0\n",
      "AdaptiveAvgPool2d-173           [32, 2048, 1, 1]               0\n",
      "          Linear-174                    [32, 6]          12,294\n",
      "================================================================\n",
      "Total params: 23,514,054\n",
      "Trainable params: 23,514,054\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.50\n",
      "Forward/backward pass size (MB): 749.00\n",
      "Params size (MB): 89.70\n",
      "Estimated Total Size (MB): 839.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "summary(ResNet50(img_channel=1, num_classes=6).to(device), input_size=(1, 64, 64), batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be1fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, checkpoint_dir=\"Resnet50_checkpoints\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}_{timestamp}.pth.tar\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer=None, checkpoint_path=\"latest_checkpoint.pth\"):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(\"Checkpoint not found!\")\n",
    "        return None\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"Checkpoint loaded from {checkpoint_path}, Epoch: {epoch}\")\n",
    "    return epoch\n",
    "\n",
    "def predict_image(model, image_path, class_labels):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path)\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        spk_rec, _ = model(image)\n",
    "        predicted_class = torch.argmax(spk_rec, dim=1).item()\n",
    "\n",
    "    print(f\"Predicted Class: {class_labels[predicted_class]}\")\n",
    "\n",
    "    # Plot image\n",
    "    plt.imshow(Image.open(image_path), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {class_labels[predicted_class]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea3c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='/content/drive/MyDrive/Spiking Visual attention in Medical Imaging/Datasets/MedicalMNIST Extracted/data/raw'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "LOAD_MODEL = False\n",
    "dtype = torch.float\n",
    "model = ResNet50(img_channel=1, num_classes=6).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(mnist_dataset))  \n",
    "test_size = len(mnist_dataset) - train_size  \n",
    "\n",
    "mnist_train, mnist_test = random_split(mnist_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(mnist_train))\n",
    "print(len(mnist_test))\n",
    "\n",
    "print(mnist_dataset.class_to_idx)\n",
    "print(mnist_dataset.classes)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3555fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    load_checkpoint(model, optimizer, \"Resnet50_checkpoints/checkpoint_epoch_4_20250408_054051.pth.tar\")\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(loss=running_loss / total, acc=100.0 * correct / total)\n",
    "        \n",
    "    save_checkpoint(model, optimizer, epoch=epoch)\n",
    "\n",
    "acc = 100 * correct / total\n",
    "print(f\"Epoch {epoch+1}, Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%\")\n",
    "\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    loop = tqdm(test_loader, desc=\"Evaluating\")\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        y_true.extend(labels.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        loop.set_postfix(acc=100.0 * correct / total)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=list(mnist_dataset.class_to_idx.keys()))\n",
    "disp.plot(xticks_rotation=45, cmap='Blues')\n",
    "plt.title(\"Confusion Matrix on Medical MNIST\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
