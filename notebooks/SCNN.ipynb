{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import backprop\n",
    "from snntorch import functional as SF\n",
    "from snntorch import utils\n",
    "from snntorch import spikeplot as splt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surrogate Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S[t] = \\Theta(U[t] - U_{\\rm thr}) \\tag{1}$$ \n",
    "$$\\frac{\\partial S}{\\partial U} = \\delta(U - U_{\\rm thr}) \\in \\{0, \\infty\\} \\tag{2}$$\n",
    "$$\\tilde{S} = \\frac{U_{OD}}{1+k|U_{OD}|} \\tag{3}$$\n",
    "$$\\frac{\\partial \\tilde{S}}{\\partial U} = \\frac{1}{(k|U_{OD}|+1)^2}\\tag{4}$$ \n",
    "$$\\tilde{S} = \\frac{U_{OD}}{1+k|U_{OD}|} \\tag{3}$$\n",
    "$$\\frac{\\partial \\tilde{S}}{\\partial U} = \\frac{1}{(k|U_{OD}|+1)^2}\\tag{4}$$\n",
    "$$\\frac{\\partial \\tilde{S}}{\\partial U} \\Bigg|_{k \\rightarrow \\infty} = \\delta(U-U_{\\rm thr})$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "\n",
    "lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "batch_size = 128\n",
    "data_path='E:/Code/SCNN-and-Resnet50-on-Medical-MNIST-classification/data/raw'\n",
    "\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47163\n",
      "11791\n",
      "{'AbdomenCT': 0, 'BreastMRI': 1, 'CXR': 2, 'ChestCT': 3, 'Hand': 4, 'HeadCT': 5}\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "mnist_dataset = datasets.ImageFolder(data_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(mnist_dataset))  # 80% for training\n",
    "test_size = len(mnist_dataset) - train_size  # 20% for testing\n",
    "\n",
    "mnist_train, mnist_test = random_split(mnist_dataset, [train_size, test_size])\n",
    "\n",
    "print(len(mnist_train))\n",
    "print(len(mnist_test))\n",
    "\n",
    "print(mnist_dataset.class_to_idx)\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n"
     ]
    }
   ],
   "source": [
    "print(mnist_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Define the Network\n",
    "\n",
    "The convolutional network architecture to be used is: 12C5-MP2-64C5-MP2-10816FC6\n",
    "\n",
    "- 12C5 is a 5X5 convolutional kernel with 12 filters\n",
    "- MP2 is a 2X2 max-pooling function\n",
    "- 64C5 is a 5X5 convolutional kernel with 64 filters\n",
    "- MP2 is another a 2X2 max-pooling function\n",
    "- 10816FC6 is a fully-connected layer that maps 10,816 neurons to 6 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neuron and simulation parameters\n",
    "spike_grad = surrogate.fast_sigmoid(slope=25)\n",
    "beta = 0.5\n",
    "num_steps = 50\n",
    "\n",
    "# Define Network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.conv1 = nn.Conv2d(1, 12, 5)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.conv2 = nn.Conv2d(12, 64, 5)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.fc1 = nn.Linear(64*13*13, 6)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # Initialize hidden states and outputs at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "\n",
    "        cur1 = F.max_pool2d(self.conv1(x), 2)\n",
    "        spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "        cur2 = F.max_pool2d(self.conv2(spk1), 2)\n",
    "        spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "        cur3 = self.fc1(spk2.view(batch_size, -1))\n",
    "        spk3, mem3 = self.lif3(cur3, mem3)\n",
    "        return spk3, mem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Conv2d(1, 12, 5),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Conv2d(12, 64, 5),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(64*13*13, 6),\n",
    "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = next(iter(train_loader))\n",
    "data = data.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "for step in range(num_steps):\n",
    "    spk_out, mem_out = net(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(net, num_steps, data):\n",
    "  mem_rec = []\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(num_steps):\n",
    "      spk_out, mem_out = net(data)\n",
    "      spk_rec.append(spk_out)\n",
    "      mem_rec.append(mem_out)\n",
    "  \n",
    "  return torch.stack(spk_rec), torch.stack(mem_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.34 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m spk_rec, mem_rec = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(net, num_steps, data)\u001b[39m\n\u001b[32m      4\u001b[39m utils.reset(net)  \u001b[38;5;66;03m# resets hidden states for all LIF neurons in net\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     spk_out, mem_out = \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     spk_rec.append(spk_out)\n\u001b[32m      9\u001b[39m     mem_rec.append(mem_out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 6.00 GiB of which 0 bytes is free. Of the allocated memory 11.34 GiB is allocated by PyTorch, and 1.32 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "spk_rec, mem_rec = forward_pass(net, num_steps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already imported snntorch.functional as SF \n",
    "loss_fn = SF.ce_rate_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss from an untrained network is 1.792\n"
     ]
    }
   ],
   "source": [
    "loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "print(f\"The loss from an untrained network is {loss_val.item():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of a single batch using an untrained network is 10.938%\n"
     ]
    }
   ],
   "source": [
    "acc = SF.accuracy_rate(spk_rec, targets)\n",
    "\n",
    "print(f\"The accuracy of a single batch using an untrained network is {acc*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(train_loader, net, num_steps):\n",
    "  with torch.no_grad():\n",
    "    total = 0\n",
    "    acc = 0\n",
    "    net.eval()\n",
    "    \n",
    "    train_loader = iter(train_loader)\n",
    "    for data, targets in train_loader:\n",
    "      data = data.to(device)\n",
    "      targets = targets.to(device)\n",
    "      spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "\n",
    "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
    "      total += spk_rec.size(1)\n",
    "\n",
    "  return acc/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total accuracy on the test set is: 17.18%\n"
     ]
    }
   ],
   "source": [
    "# test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "\n",
    "# print(f\"The total accuracy on the test set is: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(model, optimizer, epoch, checkpoint_dir=\"SCNN_checkpoints\"):\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch}_{timestamp}.pth\")\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer=None, checkpoint_path=\"latest_checkpoint.pth\"):\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        print(\"Checkpoint not found!\")\n",
    "        return None\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    epoch = checkpoint['epoch']\n",
    "    print(f\"Checkpoint loaded from {checkpoint_path}, Epoch: {epoch}\")\n",
    "    return epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, Test Acc: 17.18%\n",
      "\n",
      "Iteration 50, Test Acc: 79.98%\n",
      "\n",
      "Iteration 100, Test Acc: 80.93%\n",
      "\n",
      "Iteration 150, Test Acc: 82.26%\n",
      "\n",
      "Iteration 200, Test Acc: 82.16%\n",
      "\n",
      "Iteration 250, Test Acc: 83.00%\n",
      "\n",
      "Iteration 300, Test Acc: 82.71%\n",
      "\n",
      "Iteration 350, Test Acc: 83.20%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-2, betas=(0.9, 0.999))\n",
    "num_epochs = 1\n",
    "loss_hist = []\n",
    "test_acc_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # Training loop\n",
    "    for data, targets in iter(train_loader):\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, _ = forward_pass(net, num_steps, data)\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = loss_fn(spk_rec, targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Every 50 iterations, evaluates the model on the test set\n",
    "        if counter % 50 == 0:\n",
    "          with torch.no_grad():\n",
    "              net.eval()\n",
    "\n",
    "              # Test set forward pass\n",
    "              test_acc = batch_accuracy(test_loader, net, num_steps)\n",
    "              print(f\"Iteration {counter}, Test Acc: {test_acc * 100:.2f}%\\n\")\n",
    "              test_acc_hist.append(test_acc.item())\n",
    "\n",
    "        counter += 1\n",
    "        \n",
    "    save_checkpoint(net, optimizer, epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "train_size=47163 / batch_size=128 = iteration=368.46=350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Loss\n",
    "fig = plt.figure(facecolor=\"w\")\n",
    "plt.plot(test_acc_hist)\n",
    "plt.title(\"Test Set Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = forward_pass(net, num_steps, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 128, 10])\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49']\n"
     ]
    }
   ],
   "source": [
    "print(spk_rec.shape) \n",
    "labels = [str(i) for i in range(spk_rec.shape[0])]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The target label is: 5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (10) does not match length of index (50)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe target label is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtargets[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m#  Plot spike count histogram\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m anim = \u001b[43msplt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mspike_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspk_rec\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                        \u001b[49m\u001b[43manimate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# HTML(anim.to_html5_video())\u001b[39;00m\n\u001b[32m     15\u001b[39m anim.save(\u001b[33m\"\u001b[39m\u001b[33mspike_bar.mp4\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\snntorch\\spikeplot.py:248\u001b[39m, in \u001b[36mspike_count\u001b[39m\u001b[34m(data, fig, ax, labels, num_steps, animate, interpolate, gridshader, interval, time_step)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(xrange * interpolate):\n\u001b[32m    247\u001b[39m     idx = math.floor(i / interpolate)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[43m_plt_style\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gridshader:  \u001b[38;5;66;03m# gs appears unused but is needed by plt\u001b[39;00m\n\u001b[32m    251\u001b[39m         gs = _GridShader(  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[32m    252\u001b[39m             ax, facecolor=\u001b[33m\"\u001b[39m\u001b[33mlightgrey\u001b[39m\u001b[33m\"\u001b[39m, first=\u001b[38;5;28;01mFalse\u001b[39;00m, alpha=\u001b[32m0.7\u001b[39m\n\u001b[32m    253\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\snntorch\\spikeplot.py:338\u001b[39m, in \u001b[36m_plt_style\u001b[39m\u001b[34m(data, labels, ax, idx, time_step)\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Called by spike_count to modify style of plot.\"\"\"\u001b[39;00m\n\u001b[32m    337\u001b[39m \u001b[38;5;66;03m# spike data\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m time = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    339\u001b[39m df = pd.DataFrame({\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m: time})\n\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# numeric placeholder for the y axis\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:575\u001b[39m, in \u001b[36mSeries.__init__\u001b[39m\u001b[34m(self, data, index, dtype, name, copy, fastpath)\u001b[39m\n\u001b[32m    573\u001b[39m     index = default_index(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[32m    574\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n\u001b[32m--> \u001b[39m\u001b[32m575\u001b[39m     \u001b[43mcom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[38;5;66;03m# create/copy the manager\u001b[39;00m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Code\\Spiking-Visual-attention-for-Medical-image-segmentation\\Models\\.venv\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[39m, in \u001b[36mrequire_length_match\u001b[39m\u001b[34m(data, index)\u001b[39m\n\u001b[32m    569\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m \u001b[33;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[32m    571\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) != \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[32m--> \u001b[39m\u001b[32m573\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    574\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mLength of values \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    575\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    576\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdoes not match length of index \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    577\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    578\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Length of values (10) does not match length of index (50)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "\n",
    "fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n",
    "labels=['0', '1', '2', '3', '4', '5']\n",
    "print(f\"The target label is: {targets[idx]}\")\n",
    "\n",
    "# plt.rcParams['animation.ffmpeg_path'] = 'C:\\\\path\\\\to\\\\your\\\\ffmpeg.exe'\n",
    "\n",
    "#  Plot spike count histogram\n",
    "anim = splt.spike_count(spk_rec[:, idx].detach().cpu(), fig, ax, labels=labels, \n",
    "                        animate=True, interpolate=4)\n",
    "\n",
    "# HTML(anim.to_html5_video())\n",
    "anim.save(\"spike_bar.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, class_labels):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0).to(device)  # Add batch dimension\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        predicted_class = torch.argmax(output, dim=1).item()\n",
    "\n",
    "    print(f\"Predicted Class: {class_labels[predicted_class]}\")\n",
    "\n",
    "    # Plot image\n",
    "    plt.imshow(Image.open(image_path), cmap=\"gray\")\n",
    "    plt.title(f\"Predicted: {class_labels[predicted_class]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "class_labels = mnist_dataset.classes \n",
    "# ['AbdomenCT', 'BreastMRI', 'CXR', 'ChestCT', 'Hand', 'HeadCT']\n",
    "predict_image(net, \"test_image.jpeg\", class_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
